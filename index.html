<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Zooming</title>
  <meta name="description" content="Image zoom that makes sense.">
  <meta name="keywords" content="Image,Zoom,Image Zoom,JavaScript">
  <meta name="author" content="Pengcheng Ding">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/skeleton/2.0.4/skeleton.min.css">

  <style>
    .container {
      max-width: 1400px;
    }

    section.header {
      margin-top: 4rem;
      text-align: center;
    }

    section.content {
      text-align: center;
    }

    footer {
      text-align: center;
    }

    .value-img {
      display: block;
      text-align: center;
      margin: 2em 0;
    }

    img {
      max-width: 100%;
    }

    @media (min-width: 550px) {
      .header {
        margin-top: 10rem;
      }
    }

    .button.button-primary {
      background-color: #f9c04d !important;
      border-color: #f9c04d !important;
    }

    .button.button-secondary {
      background-color: #eee !important;
      border-color: #eee !important;
    }
  </style>

</head>

<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <h1><b>Unpuzzle Dataset Bias</b></h1>

      <h4>Nikita Jaipuria<sup>*</sup>, Katherine Stevo<sup>&dagger;</sup>, Xianling Zhang<sup>*</sup>, Meghana L. Gaopande<sup>*</sup>, Jinesh Jain<sup>*</sup>, Vidya N. Murali<sup>*</sup></h4>
      <h5><sup>*</sup>Ford Greenfield Labs, Palo Alto    <sup>&dagger;</sup>Georgia Institute of Technology</h5>
      <p style="font-size:20px"><b>Abstract</b></p>

      <p style="text-align:left">Dataset bias in manually collected datasets is a known problem in computer vision. Models trained on such datasets tend to underperform in the field. This effect is particularly amplified in automotive applications where data is hard to come by. Furthermore, in a safety-critical environment, these biases can lead to catastrophic errors jeopardizing the safety of users and their surroundings. Being able to unpuzzle the bias in a given dataset, and across datasets, is a powerful and essential tool towards building responsible AI. In this paper, we present <b>deepPIC: deep P</b>erceptual <b>I</b>mage <b>C</b>lustering, a novel data-centric hierarchical clustering pipeline that leverages deep perceptual features to visualize and understand bias in unstructured and unlabeled datasets. It does so by effectively highlighting nuanced subcategories of information embedded within the data (such as multiple but repetitive shadow types in a daytime dataset) that typically is hard and/or expensive to capture. Through experiments on a variety of image datasets, both open-source and internal to Ford, we demonstrate the effectiveness of deepPIC in singling out errors in metadata provided by open-source datasets such as BDD100K; automatic nuanced metadata annotation; mining for edge cases; visualizing inherent bias both within and across multiple automated driving datasets; and capturing synthetic data limitations; thus highlighting the wide variety of applications this pipeline can be applied to.

      <p style="text-align:left"> All the data clustering results included in the paper "Unpuzzle Dataset Bias" have been uploaded here. <b>We recommend zooming in using a touch pad for the best impact.</b>
      For desktop users without touch pad, this zoom feature will not be supported.</p>
      <br>

      <h3>Figure 2: Schematic of the hierarchical clustering pipeline, deepPIC</h3>

      <div class="value-img">
        <img id="img-default" src="assets/img/PipelineWithImages.pdf" data-action="zoom" data-original="assets/img/PipelineWithImages.pdf"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <br>

      <h3>Figure 3: 3 DBSCAN Clusters From Stage 1</h3>

      <div class="value-img">
        <img id="img-default" src="assets/img/Step2_DBSCAN_visualization.png" data-action="zoom" data-original="assets/img/Step2_DBSCAN_visualization.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>1</sup>  i.e. stage 1 output from deepPIC applied to 5000 images randomly sampled from the BDD100K training set. </p>

      <br>

      <h3>Figure 4: Stage 2 Clustering Output: C<sup>2</sup><sub>1</sub></h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step4_DBSCAN_LPIPS_just_visualization_1.png" data-action="zoom" data-original="assets/img/Step4_DBSCAN_LPIPS_just_visualization_1.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>2</sup><sub>1</sub>, i.e. stage 2 output from deepPIC applied to BDD100K images assigned to C<sup>1</sup><sub>1</sub> in Fig. 3.</p>

      <br>

      <h3>Figure 6: 12 DBSCAN Clusters from Stage 1</h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step2_VGG_visualization.png" data-action="zoom" data-original="assets/img/Step2_VGG_visualization.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>1</sup>, i.e. stage 1 output of deepPIC applied to 5000 images randomly sampled from the chair and cone object detection dataset.</p>

      <br>

      <h3>Figure 7: 3 DBSCAN Clusters From Stage 2 For C<sup>1</sup><sub>5</sub></h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step4_DBSCAN_LPIPS_distinct (1).png" data-action="zoom" data-original="assets/img/Step4_DBSCAN_LPIPS_distinct (1).png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>2</sup><sub>5</sub>, i.e. stage 2 output from deepPIC applied to the subset of images clustered in C<sup>1</sup><sub>5</sub></p>

      <br>

      <h3>Figure 7: 2 DBSCAN Clusters From Stage 2 For C<sup>1</sup><sub>2</sub></h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step4_DBSCAN_LPIPS_evolution.png" data-action="zoom" data-original="assets/img/Step4_DBSCAN_LPIPS_evolution.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>2</sup><sub>2</sub>, i.e. stage 2 output from deepPIC applied to the subset of images clustered in C<sup>1</sup><sub>2</sub></p>

      <br>

      <h3>Figure 7: 4 DBSCAN Clusters From Stage 2 For C<sup>1</sup><sub>6</sub></h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step4_DBSCAN_LPIPS_no_distinction.png" data-action="zoom" data-original="assets/img/Step4_DBSCAN_LPIPS_no_distinction.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>2</sup><sub>6</sub>, i.e. stage 2 output from deepPIC applied to the subset of images clustered in C<sup>1</sup><sub>6</sub></p>

      <br>

      <h3>Figure 8: 5 DBSCAN Clusters With Labels</h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step2_DBSCAN_5_VGG_cluster_visualization.png" data-action="zoom" data-original="assets/img/Step2_DBSCAN_5_VGG_cluster_visualization.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>Visualizing inherent dataset bias in open-source lane detection datasets. Stage 1 clustering output from deepPIC applied to 10000 images from 5 different datasets.</p>

      <br>

      <h3>Figure 9: 6 DBSCAN Clusters From Stage 1</h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Sim2Real_Image.png" data-action="zoom" data-original="assets/img/Sim2Real_Image.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>Visualizing sim-to-real gap in merged datasets. C<sup>1</sup>, i.e. stage 1 output from deepPIC applied to a mix of 3000 real, simulated and sim-to-real GAN translated parking images.</p>

      <br>

      <h3>Figure 11: Stage 2 Clustering Output</h3>

      <div class="value-img2">
        <img id="img-default" src="assets/img/Step4_DBSCAN_LPIPS_just_visualization_0.png" data-action="zoom" data-original="assets/img/Step4_DBSCAN_LPIPS_just_visualization_0.png"
          alt="journey_start_thumbnail" width="1000"/>
      </div>

      <p>C<sup>2</sup><sub>0</sub>, i.e. the stage 2 clustering output from deepPIC applied to the BDD100K images assigned to C<sup>1</sup><sub>0</sub> in Fig. 3.</p>

    </section>

<!--     <section class="content">
      <h4>Image zoom that makes sense.</h4>

      <ul>
        <li>Pure JavaScript &amp; built with mobile in mind.</li>
        <li>Smooth animations with intuitive gestures.</li>
        <li>Zoom into a hi-res image if supplied.</li>
        <li>Easy to integrate &amp; customizable.</li>
      </ul> -->
<!--
      <div class="value-img">
        <a href="assets/img/journey.jpg">
          <img id="img-custom" src="assets/img/journey_thumbnail.jpg" alt="journey_thumbnail" />
        </a>
      </div> -->
<!--
      <p>
        <small>Options below were designed to affect the second image only.</small>
      </p>
 -->
<!--       <div class="row">
        <a class="button" id="btn-fast">faster</a>
        <a class="button" id="btn-dark">dark</a>
        <a class="button" id="btn-scale-small">smaller</a>
      </div>

      <br>

      <p>
        <em>Faced with rolling sand dunes, age-old ruins, caves and howling winds, your passage will not be an easy one. The
          goal is to get to the mountaintop, but the experience is discovering who you are, what this place is, and what
          is your purpose.</em>
      </p>

      <br>

      <a class="button" href="https://github.com/kingdido999/zooming">GitHub</a>
      <a class="button button-primary" href="http://kingdido999.github.io/zooming/docs">Get Started</a>
    </section>

    <br> -->
  </div>

  <hr>

  <footer>
    <p>Created using <a href="https://github.com/kingdido999/zooming">Zooming</a></p>
  </footer>



  <script src="build/zooming.js"></script>
  <script>
    const defaultZooming = new Zooming()
    const customZooming = new Zooming()
    const config = customZooming.config()
    const TRANSITION_DURATION_DEFAULT = config.transitionDuration
    const BG_COLOR_DEFAULT = config.bgColor
    const SCALE_BASE_DEFAULT = config.scaleBase
    const ACTIVE_CLASS = 'button-primary'

    const btnFast = document.getElementById('btn-fast')
    const btnDark = document.getElementById('btn-dark')
    const btnScaleSmall = document.getElementById('btn-scale-small')

    document.addEventListener('DOMContentLoaded', function () {
      defaultZooming.listen('#img-default')
      customZooming.listen('#img-custom')
    })

    btnFast.addEventListener('click', function (event) {
      const transitionDuration = toggleActive(btnFast)
        ? 0.2
        : TRANSITION_DURATION_DEFAULT

      customZooming.config({ transitionDuration })
    })

    btnDark.addEventListener('click', function (event) {
      const bgColor = toggleActive(btnDark)
        ? 'black'
        : BG_COLOR_DEFAULT

      customZooming.config({ bgColor })
    })

    btnScaleSmall.addEventListener('click', function (event) {
      const scaleBase = toggleActive(btnScaleSmall)
        ? 3.0
        : SCALE_BASE_DEFAULT

      customZooming.config({ scaleBase })
    })

    function isActive(el) {
      return el.classList.contains(ACTIVE_CLASS)
    }

    function activate(el) {
      el.classList.add(ACTIVE_CLASS)
    }

    function deactivate(el) {
      el.classList.remove(ACTIVE_CLASS)
    }

    function toggleActive(el) {
      if (isActive(el)) {
        deactivate(el)
        return false
      } else {
        activate(el)
        return true
      }
    }

    const copyright = 'Copyright © ' +
      new Date().getFullYear() +
      ' <a href="https://github.com/kingdido999">Pengcheng Ding</a>' +
      ' and other <a href="https://github.com/kingdido999/zooming/graphs/contributors">contributors</a>'

    document.getElementById('copyright').innerHTML = copyright

  </script>
  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>

</html>
